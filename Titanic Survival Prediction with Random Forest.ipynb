{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/ez7flav5Xvpe0jwyN87L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SkyChen1009/ML-Titanic-Survival-Prediction-with-Random-Forest/blob/main/Titanic%20Survival%20Prediction%20with%20Random%20Forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries for linear algebra and data processing"
      ],
      "metadata": {
        "id": "nqx0svOSWdke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFn-5zuVWCp9"
      },
      "outputs": [],
      "source": [
        "import numpy as np  # For numerical operations on arrays\n",
        "import pandas as pd  # For data manipulation and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries for data visualization"
      ],
      "metadata": {
        "id": "g2g3GgbEoYbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns  # For advanced visualizations\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt  # For plotting data\n",
        "from matplotlib import style"
      ],
      "metadata": {
        "id": "NYm42ozroc97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import machine learning algorithms from sklearn"
      ],
      "metadata": {
        "id": "P-xyP4gSoery"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model  # For linear regression models\n",
        "from sklearn.linear_model import LogisticRegression  # For logistic regression\n",
        "from sklearn.ensemble import RandomForestClassifier  # For random forest classifier\n",
        "from sklearn.linear_model import Perceptron  # For Perceptron algorithm\n",
        "from sklearn.linear_model import SGDClassifier  # For stochastic gradient descent\n",
        "from sklearn.tree import DecisionTreeClassifier  # For decision tree classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # For k-nearest neighbors\n",
        "from sklearn.svm import SVC, LinearSVC  # For support vector machines\n",
        "from sklearn.naive_bayes import GaussianNB  # For naive bayes"
      ],
      "metadata": {
        "id": "0CHlvuozoiJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Setup"
      ],
      "metadata": {
        "id": "MpTEel2YevJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Google Drive to access data:"
      ],
      "metadata": {
        "id": "wQg_E2u7ew8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tdChmQT7WTg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "p21qYo0BfBLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load training, testing, and submission datasets:"
      ],
      "metadata": {
        "id": "S1XzM77afDi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/test.csv\")\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/train.csv\")"
      ],
      "metadata": {
        "id": "leMVuueifJ5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check for missing data\n",
        "### Summarize the total and percentage of missing data for each column"
      ],
      "metadata": {
        "id": "5hta04IDomRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total = train_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
        "missing_data.head(5)    # Display top columns with missing data"
      ],
      "metadata": {
        "id": "m_5AnXPOWcZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display column names for reference"
      ],
      "metadata": {
        "id": "fW7AmAlyorQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns.values"
      ],
      "metadata": {
        "id": "VcMgFVolW4DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize survival by gender and age using subplots"
      ],
      "metadata": {
        "id": "Joz8Q3lLoxZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "survived = 'survived'\n",
        "not_survived = 'not survived'\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10, 4))\n",
        "women = train_df[train_df['Sex']=='female']\n",
        "men = train_df[train_df['Sex']=='male']"
      ],
      "metadata": {
        "id": "Dlqcg5qyW6uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot age distribution for women based on survival"
      ],
      "metadata": {
        "id": "550jJrPNpZS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False)\n",
        "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False)\n",
        "ax.legend()\n",
        "ax.set_title('Female')"
      ],
      "metadata": {
        "id": "8_p4IE6wpU72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot age distribution for men based on survival"
      ],
      "metadata": {
        "id": "RvGtZei8pb7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False)\n",
        "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False)\n",
        "ax.legend()\n",
        "_ = ax.set_title('Male')"
      ],
      "metadata": {
        "id": "jw77eOf_pWwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FacetGrid"
      ],
      "metadata": {
        "id": "4nW98HqIppik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a FacetGrid to plot survival rate by 'Pclass' and 'Sex', with each row representing different embarkation points"
      ],
      "metadata": {
        "id": "c4SDJSWFrRZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FacetGrid = sns.FacetGrid(train_df, row='Embarked',  aspect=1.6)\n",
        "# Map a point plot to each subset of the data for visualization\n",
        "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette=None,  order=None, hue_order=None )\n",
        "# Add a legend to the FacetGrid for better interpretation of the plot\n",
        "FacetGrid.add_legend()"
      ],
      "metadata": {
        "id": "K-TbFO23W9pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot survival rate by passenger class (Pclass) as a bar plot"
      ],
      "metadata": {
        "id": "_JzmV1Dirbqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Pclass', y='Survived', data=train_df)"
      ],
      "metadata": {
        "id": "q652J-WEXKSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a FacetGrid to show the age distribution, with columns by survival status and rows by passenger class (Pclass)"
      ],
      "metadata": {
        "id": "AIkx-uL1rnOJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', aspect=1.6)\n",
        "# Map a histogram of 'Age' to each subplot in the grid\n",
        "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
        "# Add a legend to the grid for clearer distinction between facets\n",
        "grid.add_legend()"
      ],
      "metadata": {
        "id": "_9NgKMckXOto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode family-related features\n",
        "### Add 'relatives' column (sum of SibSp and Parch), and set 'not_alone' for passengers with no relatives"
      ],
      "metadata": {
        "id": "cOruijkppgXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
        "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
        "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
        "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
        "train_df['not_alone'].value_counts()"
      ],
      "metadata": {
        "id": "IIFJmC8kXUpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['PassengerId'], axis=1)"
      ],
      "metadata": {
        "id": "5rpiAy0WXhwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Map cabin decks to numerical values, filling missing 'Cabin' data with 'U0' (unknown)"
      ],
      "metadata": {
        "id": "dxrgIxf0puik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
        "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
        "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
        "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
        "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
        "# we can now drop the cabin feature\n",
        "# Drop the 'Cabin' column since 'Deck' information has been extracted\n",
        "train_df = train_df.drop(['Cabin'], axis=1)\n",
        "test_df = test_df.drop(['Cabin'], axis=1)"
      ],
      "metadata": {
        "id": "_tt9icSvXmE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handle missing values in 'Age' column by replacing them with randomly generated values within one standard deviation"
      ],
      "metadata": {
        "id": "w3Pw7MvOp0p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    mean = train_df[\"Age\"].mean()\n",
        "    std = test_df[\"Age\"].std()\n",
        "    is_null = dataset[\"Age\"].isnull().sum()\n",
        "    # compute random numbers between the mean, std and is_null\n",
        "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
        "    # fill NaN values in Age column with random values generated\n",
        "    age_slice = dataset[\"Age\"].copy()\n",
        "    age_slice[np.isnan(age_slice)] = rand_age\n",
        "    dataset[\"Age\"] = age_slice\n",
        "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
        "train_df[\"Age\"].isnull().sum()"
      ],
      "metadata": {
        "id": "Vtrb1xwCXm7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Embarked'].describe()"
      ],
      "metadata": {
        "id": "Kbw7eBOKXqfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replace missing 'Embarked' values with the most common value ('S')"
      ],
      "metadata": {
        "id": "Y6FRbpqLp8oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_value = 'S'\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
      ],
      "metadata": {
        "id": "AmhC4c3UXsf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "keeFaiKsXufR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine training and test datasets for consistent preprocessing"
      ],
      "metadata": {
        "id": "afe3aX4MqogS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    # Fill any missing 'Fare' values with 0\n",
        "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
        "    # Convert 'Fare' column to integer type for simplicity\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "metadata": {
        "id": "cw24RDEZXwpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dictionary to map title strings to numerical codes"
      ],
      "metadata": {
        "id": "cjp24oTHqxh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
        "\n",
        "for dataset in data:\n",
        "    # extract titles\n",
        "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "    # replace titles with a more common title or as Rare\n",
        "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
        "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
        "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
        "    # convert titles into numbers\n",
        "    dataset['Title'] = dataset['Title'].map(titles)\n",
        "    # filling NaN with 0, to get safe\n",
        "    dataset['Title'] = dataset['Title'].fillna(0)"
      ],
      "metadata": {
        "id": "2KTaFpzYXyxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop the 'Name' column since title information has been extracted and processed"
      ],
      "metadata": {
        "id": "C4CjaLG8q4l3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['Name'], axis=1)\n",
        "test_df = test_df.drop(['Name'], axis=1)"
      ],
      "metadata": {
        "id": "YOfgJlvRq4Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode 'Sex' feature as 0 for male and 1 for female"
      ],
      "metadata": {
        "id": "08N4k-LBqCqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genders = {\"male\": 0, \"female\": 1}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Sex'] = dataset['Sex'].map(genders)"
      ],
      "metadata": {
        "id": "saxF90lAX1D1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['Ticket'].describe()"
      ],
      "metadata": {
        "id": "1cUl1tdbX4Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drop irrelevant features (such as 'PassengerId' and 'Ticket') from the datasets"
      ],
      "metadata": {
        "id": "QwfBxjM-qGlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.drop(['Ticket'], axis=1)\n",
        "test_df = test_df.drop(['Ticket'], axis=1)"
      ],
      "metadata": {
        "id": "s3pOgo1gX6hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset['Embarked'] = dataset['Embarked'].map(ports)"
      ],
      "metadata": {
        "id": "Y737cNygX8WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
        "\n",
        "# let's see how it's distributed train_df['Age'].value_counts()"
      ],
      "metadata": {
        "id": "BR3n_DhAcgjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "K6l52Ng1dLDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
        "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
        "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
        "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
        "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
        "    dataset['Fare'] = dataset['Fare'].astype(int)"
      ],
      "metadata": {
        "id": "Aexji09DdOr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [train_df, test_df]\n",
        "for dataset in data:\n",
        "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
      ],
      "metadata": {
        "id": "uR1vhmvBdRF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in data:\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
        "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
        "# Let's take a last look at the training set, before we start training the models.\n",
        "train_df.head(10)"
      ],
      "metadata": {
        "id": "wzmUDhUpdTSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for model training\n",
        "### Separate the features (X_train) and target variable (Y_train)"
      ],
      "metadata": {
        "id": "iHcuFDDCqL_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.drop(\"Survived\", axis=1)\n",
        "Y_train = train_df[\"Survived\"]\n",
        "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()"
      ],
      "metadata": {
        "id": "URrtgjBrdVYx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}